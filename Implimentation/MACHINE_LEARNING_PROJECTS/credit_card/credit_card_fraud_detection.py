# -*- coding: utf-8 -*-
"""Credit Card Fraud Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UEXK8Q83v7bMwI8faixm1lVCKbKw55_v
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import numpy as np
from sklearn.linear_model import LogisticRegression

#importing the data
df=pd.read_csv('/content/creditcard.csv')

df.head()
df.tail()
df.describe()

df.shape
df.isnull().sum()

# fig, ax = plt.subplots(figsize=(8, 8))
# # sns.distplot(df.V20)
# df[['V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28']].fillna(df[['V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28']].mode(), inplace=True)

df['Class'].value_counts()

legit=df[df.Class==0]
fraud=df[df.Class==1]

print(legit.shape)
print(fraud.shape)

#statistical measures of the data
legit.Amount.describe()

fraud.Amount.describe()

#compare the values for both transactions
df.groupby('Class').mean()

#undersampling
#build a sample dataset containg similar distributon of normal transactions anf fraudulent transactions
#number of fraudulent trasaction ==52

legit_sample=legit.sample(n=52)

#concatinating 2 data set
newdf=pd.concat([legit_sample,fraud],axis=0)

newdf.head()

newdf.shape

#splitting the test and trainding data
X=newdf.drop(columns='Class',axis=1)
Y=newdf['Class']

print(X)
print(Y)

x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,stratify=Y,random_state=2)

#model trainging
#logistic regression
model=LogisticRegression()
model.fit(x_train,y_train)

#evaluation of the model
#accuracy score
x_train_prediction=model.predict(x_train)
training_data_accuracy=accuracy_score(x_train_prediction,y_train)
print(training_data_accuracy)
#accuracy on test data
x_test_prediction=model.predict(x_test)
test_data_accuracy=accuracy_score(x_test_prediction,y_test)
print(test_data_accuracy)